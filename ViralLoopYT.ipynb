{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQikubc40FUS8Ht4SnHpZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshyag123/ViralLoopYT/blob/main/ViralLoopYT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKTeHaJxp3MM",
        "outputId": "4222b4d4-bc7b-4a05-a8f4-b930163e18d3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
            "Requirement already satisfied: instaloader in /usr/local/lib/python3.12/dist-packages (4.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gtts) (8.1.8)\n"
          ]
        }
      ],
      "source": [
        "!apt-get -y install ffmpeg\n",
        "!pip install instaloader requests gtts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_L5qU1Ji9_A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import urllib.parse\n",
        "import os\n",
        "\n",
        "# Check if running in Colab or GitHub Actions\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Get credentials based on environment\n",
        "if IN_COLAB:\n",
        "    REDIS_URL = userdata.get(\"UPSTASH_REDIS_REST_URL\")\n",
        "    REDIS_TOKEN = userdata.get(\"UPSTASH_REDIS_REST_TOKEN\")\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    client_secret = userdata.get(\"YT_CLIENT_SECRET\")\n",
        "    token_secret = userdata.get(\"YT_TOKEN\")\n",
        "else:\n",
        "    # Running in GitHub Actions or locally\n",
        "    REDIS_URL = os.environ.get(\"UPSTASH_REDIS_REST_URL\")\n",
        "    REDIS_TOKEN = os.environ.get(\"UPSTASH_REDIS_REST_TOKEN\")\n",
        "    HF_TOKEN = os.environ.get('HF_TOKEN')\n",
        "    client_secret = os.environ.get(\"YT_CLIENT_SECRET\")\n",
        "    token_secret = os.environ.get(\"YT_TOKEN\")"
      ],
      "metadata": {
        "id": "vKg7oiPK3Cq2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #https://console.upstash.com/redis/ce919edb-411b-47a5-b03c-c5125ee1bb22/details?teamid=0(REDIS)\n",
        "# import requests\n",
        "# from google.colab import userdata\n",
        "\n",
        "# REDIS_URL = userdata.get(\"UPSTASH_REDIS_REST_URL\")\n",
        "# REDIS_TOKEN = userdata.get(\"UPSTASH_REDIS_REST_TOKEN\")\n",
        "\n",
        "# if not REDIS_URL or not REDIS_TOKEN:\n",
        "#     raise Exception(\"‚ùå Missing Redis secrets\")\n",
        "\n",
        "# HEADERS = {\"Authorization\": f\"Bearer {REDIS_TOKEN}\"}\n",
        "# REDIS_SET_KEY = \"uploaded_reels\"\n",
        "\n",
        "# def is_already_uploaded(reel_id: str) -> bool:\n",
        "#     r = requests.get(\n",
        "#         f\"{REDIS_URL}/sismember/{REDIS_SET_KEY}/{reel_id}\",\n",
        "#         headers=HEADERS,\n",
        "#         timeout=10\n",
        "#     )\n",
        "#     print(f\"response:{r.text}\")\n",
        "#     return r.text == \"1\"\n",
        "\n",
        "# def mark_as_uploaded(reel_id: str):\n",
        "#     requests.post(\n",
        "#         f\"{REDIS_URL}/sadd/{REDIS_SET_KEY}/{reel_id}\",\n",
        "#         headers=HEADERS,\n",
        "#         timeout=10\n",
        "#     )\n"
      ],
      "metadata": {
        "id": "7nUFsvI33emI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import urllib.parse\n",
        "#from google.colab import userdata\n",
        "\n",
        "# REDIS_URL = userdata.get(\"UPSTASH_REDIS_REST_URL\")\n",
        "# REDIS_TOKEN = userdata.get(\"UPSTASH_REDIS_REST_TOKEN\")\n",
        "\n",
        "if not REDIS_URL or not REDIS_TOKEN:\n",
        "    raise Exception(\"‚ùå Missing Redis secrets\")\n",
        "\n",
        "HEADERS = {\"Authorization\": f\"Bearer {REDIS_TOKEN}\"}\n",
        "REDIS_SET_KEY = \"uploaded_reels\"\n",
        "\n",
        "\n",
        "def is_already_uploaded(reel_id: str) -> bool:\n",
        "    reel_id = urllib.parse.quote(reel_id)\n",
        "\n",
        "    r = requests.get(\n",
        "        f\"{REDIS_URL}/sismember/{REDIS_SET_KEY}/{reel_id}\",\n",
        "        headers=HEADERS,\n",
        "        timeout=10\n",
        "    )\n",
        "\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "\n",
        "    # Upstash returns {\"result\": 0 or 1}\n",
        "    result = data.get(\"result\", 0)\n",
        "\n",
        "    print(f\"üß† Redis check {reel_id}: {result}\")\n",
        "    return result == 1\n",
        "\n",
        "\n",
        "def mark_as_uploaded(reel_id: str):\n",
        "    reel_id = urllib.parse.quote(reel_id)\n",
        "\n",
        "    r = requests.post(\n",
        "        f\"{REDIS_URL}/sadd/{REDIS_SET_KEY}/{reel_id}\",\n",
        "        headers=HEADERS,\n",
        "        timeout=10\n",
        "    )\n",
        "\n",
        "    r.raise_for_status()\n"
      ],
      "metadata": {
        "id": "lCSRNANqsRm9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def print_all_uploaded_reels():\n",
        "#     r = requests.get(\n",
        "#         f\"{REDIS_URL}/smembers/{REDIS_SET_KEY}\",\n",
        "#         headers=HEADERS,\n",
        "#         timeout=10\n",
        "#     )\n",
        "\n",
        "#     if r.status_code != 200:\n",
        "#         raise Exception(\"‚ùå Failed to fetch Redis set\")\n",
        "\n",
        "#     reels = r.json().get(\"result\", [])\n",
        "\n",
        "#     if not reels:\n",
        "#         print(\"üì≠ Redis set is empty (no reels uploaded yet)\")\n",
        "#         return\n",
        "\n",
        "#     print(f\"üì¶ Total uploaded reels: {len(reels)}\\n\")\n",
        "#     for reel in reels:\n",
        "#         print(reel)\n",
        "\n",
        "# # Call it\n",
        "# print_all_uploaded_reels()"
      ],
      "metadata": {
        "id": "kjlr3nT38l-D"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import instaloader\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "\n",
        "# Clean old files\n",
        "if os.path.exists(\"reels\"):\n",
        "    shutil.rmtree(\"reels\")\n",
        "os.makedirs(\"reels\", exist_ok=True)\n",
        "\n",
        "PUBLIC_PAGES = [\"our.littlejoys\"]\n",
        "\n",
        "L = instaloader.Instaloader(\n",
        "    download_pictures=False,\n",
        "    download_video_thumbnails=False,\n",
        "    save_metadata=False, # Disables JSON, but .txt caption is still created\n",
        "    compress_json=False\n",
        ")\n",
        "\n",
        "def get_video_duration(video_path):\n",
        "    cmd = [\n",
        "        \"ffprobe\", \"-v\", \"error\",\n",
        "        \"-show_entries\", \"format=duration\",\n",
        "        \"-of\", \"default=noprint_wrappers=1:nokey=1\",\n",
        "        video_path\n",
        "    ]\n",
        "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    return float(result.stdout.decode().strip())\n",
        "\n",
        "def download_one_reel():\n",
        "    page = random.choice(PUBLIC_PAGES)\n",
        "    print(\"Selected page:\", page)\n",
        "\n",
        "    profile = instaloader.Profile.from_username(L.context, page)\n",
        "\n",
        "    # 1Ô∏è‚É£ Collect a pool of video posts\n",
        "    video_posts = []\n",
        "    MAX_POOL = 15\n",
        "\n",
        "    for post in profile.get_posts():\n",
        "        if post.is_video:\n",
        "            video_posts.append(post)\n",
        "        if len(video_posts) >= MAX_POOL:\n",
        "            break\n",
        "\n",
        "    if not video_posts:\n",
        "        raise Exception(\"No video posts found\")\n",
        "\n",
        "    # 2Ô∏è‚É£ Shuffle pool to randomize attempts\n",
        "    random.shuffle(video_posts)\n",
        "\n",
        "    selected_post = None\n",
        "\n",
        "    for post in video_posts:\n",
        "        if not is_already_uploaded(post.shortcode):\n",
        "            selected_post = post\n",
        "            break\n",
        "        else:\n",
        "            print(f\"‚è≠Ô∏è Skipping already uploaded reel: {post.shortcode}\")\n",
        "\n",
        "    # 3Ô∏è‚É£ If ALL reels are already uploaded\n",
        "    if not selected_post:\n",
        "        raise Exception(\"‚ùå All reels in this page are already uploaded\")\n",
        "\n",
        "    print(\"üéØ Selected NEW reel:\", selected_post.shortcode)\n",
        "\n",
        "    # 4Ô∏è‚É£ Download ONLY that reel\n",
        "    L.download_post(selected_post, target=\"reels\")\n",
        "    time.sleep(8)\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    video_path = \"\"\n",
        "\n",
        "    # 5Ô∏è‚É£ Rename downloaded files\n",
        "    for f in os.listdir(\"reels\"):\n",
        "        old_path = os.path.join(\"reels\", f)\n",
        "\n",
        "        if f.endswith(\".mp4\") and not f.startswith(\"reel_\"):\n",
        "            new_video_name = f\"reel_{timestamp}.mp4\"\n",
        "            video_path = os.path.join(\"reels\", new_video_name)\n",
        "            os.rename(old_path, video_path)\n",
        "\n",
        "        elif f.endswith(\".txt\") and not f.startswith(\"caption_\"):\n",
        "            new_txt_name = f\"caption_{timestamp}.txt\"\n",
        "            os.rename(old_path, os.path.join(\"reels\", new_txt_name))\n",
        "            print(f\"‚úÖ Caption saved as: {new_txt_name}\")\n",
        "\n",
        "    # ‚úÖ HARD SAFETY CHECK (THIS WAS MISSING)\n",
        "    if not video_path or not os.path.exists(video_path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Downloaded video file not found in reels/. Files: {os.listdir('reels')}\"\n",
        "        )\n",
        "\n",
        "    # 6Ô∏è‚É£ Mark reel as uploaded in Redis\n",
        "    mark_as_uploaded(selected_post.shortcode)\n",
        "    print(\"üß† Saved reel ID to Redis:\", selected_post.shortcode)\n",
        "\n",
        "    duration = get_video_duration(video_path)\n",
        "    return video_path, page, duration\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "VIDEO_FILE, SOURCE_PAGE, DURATION = download_one_reel()\n",
        "\n",
        "print(\"Downloaded ONE video:\", VIDEO_FILE)\n",
        "print(f\"Reel duration: {DURATION:.2f} seconds\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrBuFNVJrVQ_",
        "outputId": "089a157c-d87c-4840-8d1b-7ec3c459959e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected page: our.littlejoys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "JSON Query to graphql/query: Expecting value: line 1 column 1 (char 0) [retrying; skip with ^C]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Redis check DSfPcT_DKvU: 0\n",
            "üéØ Selected NEW reel: DSfPcT_DKvU\n",
            "[Fueling festive play with car‚Ä¶] reels/2025-12-20_14-11-45_UTC.mp4 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "# HF_TOKEN = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "_U2Vw_PcpWgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "client = InferenceClient(\n",
        "    model=MODEL_ID,\n",
        "    api_key=HF_TOKEN,   # must be valid (paid endpoint or allowed model)\n",
        ")\n",
        "\n",
        "def generate_script_hf(insta_caption):\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": (\n",
        "                        \"Create a viral video hook and short spoken script.\\n\\n\"\n",
        "                        f\"Instagram caption:\\n\\\"{insta_caption}\\\"\\n\\n\"\n",
        "                        \"Rules:\\n\"\n",
        "                        \"- Hook: max 6 words\\n\"\n",
        "                        \"- Script: max 30 words\\n\"\n",
        "                        \"- Simple spoken English\\n\"\n",
        "                        \"- No emojis, no hashtags, no brand promotions\\n\\n\"\n",
        "                        \"Return ONLY in this format:\\n\"\n",
        "                        \"Hook: ...\\n\"\n",
        "                        \"Script: ...\"\n",
        "                    )\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=120,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "\n",
        "        text = completion.choices[0].message.content\n",
        "\n",
        "        hook_part = re.search(r\"Hook:(.*?)Script:\", text, re.S | re.I)\n",
        "        script_part = re.search(r\"Script:(.*)\", text, re.S | re.I)\n",
        "\n",
        "        hook = hook_part.group(1).strip() if hook_part else \"Check this out\"\n",
        "        script = script_part.group(1).strip() if script_part else \"This clip surprised everyone watching.\"\n",
        "\n",
        "        print(\"‚úÖ HF Chat Completion API called successfully\")\n",
        "        return hook[:50], script[:120]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è HF API error: {e}\")\n",
        "        return \"Check this out\", \"This clip surprised everyone watching.\"\n"
      ],
      "metadata": {
        "id": "vTPOA4ch0VlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Manual\n",
        "# # import os\n",
        "# # import subprocess\n",
        "# # from gtts import gTTS\n",
        "\n",
        "# # # --- 4. VOICE & VIDEO PRODUCTION ---\n",
        "# # print(\"üé¨ Merging Voice and Video...\")\n",
        "\n",
        "# # # 1. Find the latest caption file\n",
        "# # caption_file = VIDEO_FILE.replace(\"reel_\", \"caption_\").replace(\".mp4\", \".txt\")\n",
        "\n",
        "# # if os.path.exists(caption_file):\n",
        "# #     with open(caption_file, \"r\", encoding=\"utf-8\") as f:\n",
        "# #         actual_caption = f.read().strip()\n",
        "\n",
        "# #     # DEFINE HOOK: Use the first 5 words of the caption for the visual overlay\n",
        "# #     words = actual_caption.split()\n",
        "# #     HOOK = \" \".join(words[:5]) + \"...\" if len(words) > 5 else actual_caption\n",
        "# #     print(f\"üìñ Using caption for voice. Hook for overlay: {HOOK}\")\n",
        "# # else:\n",
        "# #     # FALLBACK: If txt is missing, use standard defaults\n",
        "# #     actual_caption = \"Check out this amazing satisfying moment!\"\n",
        "# #     HOOK = \"Satisfying Discovery!\"\n",
        "# #     print(\"‚ö†Ô∏è Caption file not found, using generic fallback.\")\n",
        "\n",
        "# # # 2. Generate Voice from the FULL caption\n",
        "# # gTTS(text=actual_caption, lang='en').save(\"voice2.mp3\")\n",
        "\n",
        "# # # 3. Merge with FFmpeg (Now HOOK is defined)\n",
        "# # subprocess.run([\n",
        "# #     \"ffmpeg\", \"-y\",\n",
        "# #     \"-i\", VIDEO_FILE,\n",
        "# #     \"-i\", \"voice2.mp3\",\n",
        "# #     \"-filter_complex\",\n",
        "# #     # Audio Mix: Background at 30%, Voice at 200%\n",
        "# #     \"[0:a]volume=0.3[a_orig];[1:a]volume=2.0[a_voice];[a_orig][a_voice]amix=inputs=2:duration=first[outa];\"\n",
        "# #     # Visual Overlay: Uses the HOOK variable we just defined\n",
        "# #     f\"[0:v]drawtext=text='{HOOK}':fontcolor=white:fontsize=30:box=1:boxcolor=black@0.6:x=(w-tw)/2:y=h-th-150[outv]\",\n",
        "# #     \"-map\", \"[outv]\",\n",
        "# #     \"-map\", \"[outa]\",\n",
        "# #     \"-c:v\", \"libx264\",\n",
        "# #     \"-preset\", \"ultrafast\",\n",
        "# #     \"final_short2.mp4\"\n",
        "# # ])\n",
        "\n",
        "# # print(\"\\nüèÜ SUCCESS: final_short2.mp4 generated with caption-based text and voice.\")\n",
        "\n",
        "# #LLM\n",
        "# import os\n",
        "# import subprocess\n",
        "# from gtts import gTTS\n",
        "\n",
        "# print(\"üé¨ Merging Voice and Video (HF-powered)...\")\n",
        "\n",
        "# # 1. Locate caption file\n",
        "# def find_latest_caption():\n",
        "#     captions = [\n",
        "#         os.path.join(\"reels\", f)\n",
        "#         for f in os.listdir(\"reels\")\n",
        "#         if f.startswith(\"caption_\") and f.endswith(\".txt\")\n",
        "#     ]\n",
        "#     if not captions:\n",
        "#         return None\n",
        "#     # Pick the latest caption file\n",
        "#     return max(captions, key=os.path.getmtime)\n",
        "\n",
        "\n",
        "# caption_file = find_latest_caption()\n",
        "\n",
        "# if caption_file and os.path.exists(caption_file):\n",
        "#     with open(caption_file, \"r\", encoding=\"utf-8\") as f:\n",
        "#         actual_caption = f.read().strip()\n",
        "#     print(f\"üìÑ Using caption file: {caption_file}\")\n",
        "# else:\n",
        "#     actual_caption = \"Check out this amazing satisfying moment!\"\n",
        "#     print(\"‚ö†Ô∏è Caption file not found, using fallback\")\n",
        "\n",
        "\n",
        "# # if os.path.exists(caption_file):\n",
        "# #     with open(caption_file, \"r\", encoding=\"utf-8\") as f:\n",
        "# #         actual_caption = f.read().strip()\n",
        "\n",
        "# #     # DEFINE HOOK: Use the first 5 words of the caption for the visual overlay\n",
        "# #     words = actual_caption.split()\n",
        "# #     HOOK = \" \".join(words[:5]) + \"...\" if len(words) > 5 else actual_caption\n",
        "# # else:\n",
        "# #     actual_caption = \"Check out this amazing satisfying moment!\"\n",
        "# #     print(\"‚ö†Ô∏è Caption file not found, using fallback\")\n",
        "\n",
        "# # 2. üî• CALL YOUR HF API (Hook + Script)\n",
        "# HOOK, SCRIPT = generate_script_hf(actual_caption)\n",
        "\n",
        "# print(\"üéØ HOOK:\", HOOK) # the text displayed on the screen\n",
        "# print(\"üó£Ô∏è SCRIPT:\", SCRIPT) # the voice script that is spoken by AI\n",
        "\n",
        "# # 3. Generate voice from SCRIPT (NOT full caption)\n",
        "# gTTS(text=SCRIPT, lang=\"en\").save(\"voice.mp3\")\n",
        "\n",
        "# # 4. Merge voice + video + HOOK overlay\n",
        "# subprocess.run([\n",
        "#     \"ffmpeg\", \"-y\",\n",
        "#     \"-i\", VIDEO_FILE,\n",
        "#     \"-i\", \"voice.mp3\",\n",
        "#     \"-filter_complex\",\n",
        "#     # Audio mix\n",
        "#     \"[0:a]volume=0.3[a_orig];\"\n",
        "#     \"[1:a]volume=2.0[a_voice];\"\n",
        "#     \"[a_orig][a_voice]amix=inputs=2:duration=first[outa];\"\n",
        "#     # Text overlay using HOOK from LLM\n",
        "#     f\"[0:v]drawtext=text='{HOOK}':\"\n",
        "#     \"fontcolor=white:fontsize=30:box=1:boxcolor=black@0.6:\"\n",
        "#     \"x=(w-tw)/2:y=h-th-150[outv]\",\n",
        "#     \"-map\", \"[outv]\",\n",
        "#     \"-map\", \"[outa]\",\n",
        "#     \"-c:v\", \"libx264\",\n",
        "#     \"-preset\", \"ultrafast\",\n",
        "#     \"final_short.mp4\"\n",
        "# ])\n",
        "\n",
        "# print(\"\\nüèÜ SUCCESS: final_short.mp4 generated using HF Hook + Script.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GVvo0Gxf0goW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from gtts import gTTS\n",
        "\n",
        "print(\"üé¨ Merging Voice and Video (HF-powered)...\")\n",
        "\n",
        "WATERMARK = \"üç´\"\n",
        "\n",
        "# 1. Locate caption file\n",
        "def find_latest_caption():\n",
        "    captions = [\n",
        "        os.path.join(\"reels\", f)\n",
        "        for f in os.listdir(\"reels\")\n",
        "        if f.startswith(\"caption_\") and f.endswith(\".txt\")\n",
        "    ]\n",
        "    return max(captions, key=os.path.getmtime) if captions else None\n",
        "\n",
        "\n",
        "caption_file = find_latest_caption()\n",
        "\n",
        "if caption_file and os.path.exists(caption_file):\n",
        "    with open(caption_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        actual_caption = f.read().strip()\n",
        "else:\n",
        "    actual_caption = \"Check out this amazing satisfying moment!\"\n",
        "\n",
        "# 2. Generate script\n",
        "_, SCRIPT = generate_script_hf(actual_caption)\n",
        "\n",
        "# 3. Generate voice\n",
        "gTTS(text=SCRIPT, lang=\"en\").save(\"voice.mp3\")\n",
        "\n",
        "# 4. Merge voice + video + TRANSPARENT EMOJI WATERMARK\n",
        "subprocess.run([\n",
        "    \"ffmpeg\", \"-y\",\n",
        "    \"-i\", VIDEO_FILE,\n",
        "    \"-i\", \"voice.mp3\",\n",
        "    \"-filter_complex\",\n",
        "    # Audio mix\n",
        "    \"[0:a]volume=0.3[a_orig];\"\n",
        "    \"[1:a]volume=2.0[a_voice];\"\n",
        "    \"[a_orig][a_voice]amix=inputs=2:duration=first[outa];\"\n",
        "    # Bottom-right transparent watermark with emoji\n",
        "    f\"[0:v]drawtext=text='{WATERMARK}':\"\n",
        "    \"fontfile=/usr/share/fonts/truetype/noto/NotoColorEmoji.ttf:\"\n",
        "    \"fontsize=38:\"\n",
        "    \"fontcolor=white@0.55:\"\n",
        "    \"x=w-tw-30:y=h-th-30[outv]\",\n",
        "    \"-map\", \"[outv]\",\n",
        "    \"-map\", \"[outa]\",\n",
        "    \"-c:v\", \"libx264\",\n",
        "    \"-preset\", \"ultrafast\",\n",
        "    \"final_short.mp4\"\n",
        "])\n",
        "\n",
        "print(\"\\nüèÜ SUCCESS: final_short.mp4 generated with transparent emoji watermark.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yoNyVHRsfeMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import userdata\n",
        "\n",
        "CLIENT_SECRET_FILE = \"client_secret.json\"\n",
        "TOKEN_FILE = \"token.json\"\n",
        "\n",
        "# client_secret = userdata.get(\"YT_CLIENT_SECRET\")\n",
        "# token_secret = userdata.get(\"YT_TOKEN\")\n",
        "\n",
        "if not client_secret or not token_secret:\n",
        "    raise Exception(\"‚ùå Missing Colab secrets: YT_CLIENT_SECRET / YT_TOKEN\")\n",
        "\n",
        "with open(CLIENT_SECRET_FILE, \"w\") as f:\n",
        "    f.write(client_secret)\n",
        "\n",
        "with open(TOKEN_FILE, \"w\") as f:\n",
        "    f.write(token_secret)\n",
        "\n",
        "print(\"‚úÖ Secrets restored from Colab userdata\")\n"
      ],
      "metadata": {
        "id": "yZH4jfv3V9Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2\n"
      ],
      "metadata": {
        "id": "kUqflhrqYmoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Code to generate token\n",
        "\n",
        "# import os, json, re\n",
        "# from google_auth_oauthlib.flow import Flow\n",
        "\n",
        "# # This allows the use of http (insecure) for the localhost redirect\n",
        "# os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
        "\n",
        "\n",
        "# # 1. SETUP - Use 8090 to avoid the 'node' process conflict\n",
        "# REDIRECT_URI = \"http://localhost:8090/\"\n",
        "\n",
        "# SCOPES = [\"https://www.googleapis.com/auth/youtube.upload\"]\n",
        "\n",
        "\n",
        "# # 2. CREATE FLOW\n",
        "# # flow = Flow.from_client_secrets_file(\n",
        "# #     'client_secret.json',\n",
        "# #     scopes=SCOPES,\n",
        "# #     redirect_uri=REDIRECT_URI\n",
        "# # )\n",
        "\n",
        "# flow = Flow.from_client_secrets_file(\n",
        "#     CLIENT_SECRET_FILE,\n",
        "#     scopes=SCOPES,\n",
        "#     redirect_uri=REDIRECT_URI\n",
        "# )\n",
        "\n",
        "# # 3. GENERATE AUTH URL\n",
        "# auth_url, _ = flow.authorization_url(prompt='consent', access_type='offline')\n",
        "# print(f\"1. Click here to authorize: {auth_url}\")\n",
        "\n",
        "# # 4. MANUAL CAPTURE\n",
        "# print(\"\\nInstructions for Colab:\")\n",
        "# print(\"After clicking 'Allow', the browser will fail to load a page at 'localhost:8090'.\")\n",
        "# print(\"Copy the FULL URL from your browser's address bar (starts with http://localhost:8090/...)\")\n",
        "# auth_response = input(\"\\n2. Paste that FULL URL here: \").strip()\n",
        "\n",
        "# # 5. FETCH AND SAVE PERMANENT TOKEN\n",
        "# flow.fetch_token(authorization_response=auth_response)\n",
        "# with open(\"token.json\", \"w\") as token:\n",
        "#     token.write(flow.credentials.to_json())\n",
        "\n",
        "# print(\"\\n‚úÖ SUCCESS! 'token.json' created using port 8090.\")\n"
      ],
      "metadata": {
        "id": "plGulTdNgvYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_caption_text():\n",
        "    for f in os.listdir(\"reels\"):\n",
        "        if f.startswith(\"caption_\") and f.endswith(\".txt\"):\n",
        "            with open(os.path.join(\"reels\", f), \"r\", encoding=\"utf-8\") as file:\n",
        "                text = file.read().strip()\n",
        "                return text if text else None\n",
        "    return None\n",
        "\n",
        "CAPTION_TEXT = read_caption_text()\n",
        "\n",
        "print(\"üìÑ Caption text loaded:\\n\", CAPTION_TEXT)\n"
      ],
      "metadata": {
        "id": "SjqUdqosFpqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.oauth2.credentials import Credentials\n",
        "import googleapiclient.discovery\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "SCOPES = [\"https://www.googleapis.com/auth/youtube.upload\"]\n",
        "# TOKEN_FILE = \"token.json\"\n",
        "CLIENT_SECRET_FILE = \"/content/drive/MyDrive/youtube_secrets/client_secret.json\"\n",
        "\n",
        "def get_youtube_service():\n",
        "    creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)\n",
        "    return googleapiclient.discovery.build(\n",
        "        \"youtube\", \"v3\", credentials=creds\n",
        "    )\n",
        "\n",
        "def upload_video(\n",
        "    video_path,\n",
        "    title,\n",
        "    description,\n",
        "    tags,\n",
        "    privacy_status=\"public\"\n",
        "):\n",
        "    youtube = get_youtube_service()\n",
        "\n",
        "    request_body = {\n",
        "        \"snippet\": {\n",
        "            \"title\": title,\n",
        "            \"description\": description,\n",
        "            \"tags\": tags or [],\n",
        "            \"categoryId\": \"22\"  # People & Blogs (good for Shorts)\n",
        "        },\n",
        "        \"status\": {\n",
        "            \"privacyStatus\": privacy_status,\n",
        "            \"selfDeclaredMadeForKids\": False\n",
        "        }\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(\n",
        "        video_path,\n",
        "        chunksize=-1,\n",
        "        resumable=True\n",
        "    )\n",
        "\n",
        "    request = youtube.videos().insert(\n",
        "        part=\"snippet,status\",\n",
        "        body=request_body,\n",
        "        media_body=media\n",
        "    )\n",
        "\n",
        "    response = request.execute()\n",
        "    video_id = response[\"id\"]\n",
        "    print(\"‚úÖ Uploaded video URL: https://www.youtube.com/watch?v=\" + video_id)\n",
        "    return response[\"id\"]\n"
      ],
      "metadata": {
        "id": "Tg4q8qOMpKJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "\n",
        "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "client = InferenceClient(\n",
        "    model=MODEL_ID,\n",
        "    api_key=HF_TOKEN\n",
        ")\n",
        "\n",
        "\n",
        "def default_metadata():\n",
        "    return (\n",
        "        \"Viral Video #shorts\",\n",
        "        \"Watch till the end! #shorts\",\n",
        "        [\"shorts\", \"viral\"]\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_metadata_hf(insta_caption):\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"Return ONLY in this format:\\n\"\n",
        "                        \"Title: ...\\n\"\n",
        "                        \"Description: ...\\n\"\n",
        "                        \"Tags: ...\"\n",
        "                    )\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": (\n",
        "                        \"Create YouTube Shorts metadata.\\n\\n\"\n",
        "                        f\"Instagram caption:\\n\\\"{insta_caption}\\\"\\n\\n\"\n",
        "                        \"Rules:\\n\"\n",
        "                        \"- Title < 60 characters and include #shorts\\n\"\n",
        "                        \"- Description: detailed description with trending and latest viral hashtags\\n\"\n",
        "                        \"- Tags: comma separated, max 10\\n\"\n",
        "                        \"- No emojis\"\n",
        "                    )\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=300,\n",
        "            temperature=0.9,\n",
        "        )\n",
        "\n",
        "        text = completion.choices[0].message.content\n",
        "\n",
        "        # üîé Regex parsing (same logic as your original)\n",
        "        title_match = re.search(r\"Title:(.*?)Description:\", text, re.S | re.I)\n",
        "        desc_match = re.search(r\"Description:(.*?)Tags:\", text, re.S | re.I)\n",
        "        tags_match = re.search(r\"Tags:(.*)\", text, re.S | re.I)\n",
        "\n",
        "        title = title_match.group(1).strip() if title_match else \"Viral Video #shorts\"\n",
        "        description = desc_match.group(1).strip() if desc_match else \"Check this out! #shorts\"\n",
        "        tags_raw = tags_match.group(1).strip() if tags_match else \"shorts,viral\"\n",
        "\n",
        "        tags = [t.strip() for t in tags_raw.split(\",\") if t.strip()][:10]\n",
        "\n",
        "        print(\"‚úÖ HF Metadata API called successfully\")\n",
        "        return title[:60], description[:200], tags\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è HF Metadata Error: {e}\")\n",
        "        return default_metadata()\n",
        "\n"
      ],
      "metadata": {
        "id": "oCrWM9ikKaiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_FILE = \"final_short.mp4\"\n",
        "\n",
        "#LLM\n",
        "TITLE, DESCRIPTION, TAGS = generate_metadata_hf(SCRIPT)\n",
        "\n",
        "print(\"üé¨ TITLE:\", TITLE)\n",
        "print(\"üìù DESCRIPTION:\", DESCRIPTION)\n",
        "print(\"üè∑Ô∏è TAGS:\", TAGS)\n",
        "\n",
        "#Manual\n",
        "# TITLE = \"New Viral Video\"\n",
        "# DESCRIPTION = \"Watch till the end! #shorts\"\n",
        "# TAGS = [\"shorts\", \"satisfying\", \"viral\"]\n",
        "\n",
        "# YT Upload Method\n",
        "upload_video(\n",
        "    video_path=VIDEO_FILE,\n",
        "    title=TITLE,\n",
        "    description=DESCRIPTION,\n",
        "    tags=TAGS,\n",
        "    privacy_status=\"public\"  # or \"private\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "zdu2KRWNpWMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}